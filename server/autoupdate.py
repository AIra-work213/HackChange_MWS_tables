# -*- coding: utf-8 -*-
"""–∞–≤—Ç–æ–æ–±–Ω–æ–≤–∞

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hk_1HcQ4Z7yOjMQF-1f0gDhrqw4qS9RO
"""

import requests
import pandas as pd
import numpy as np
from tqdm import tqdm
import time
import logging
from datetime import datetime, timedelta
import warnings
import concurrent.futures
from threading import Lock
import random

# –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings('ignore', category=FutureWarning)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.WARNING)

# –°–ª–æ–≤–∞—Ä—å –≥—Ä—É–ø–ø –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ —Å–≤—è–∑–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ (ID -> –Ω–∞–∑–≤–∞–Ω–∏–µ)
VK_GROUPS = {
    '-8458649': '–ú–¢–°',    # –ú–¢–°
    '-26514504': '–ë–∏–ª–∞–π–Ω', # –ë–∏–ª–∞–π–Ω
    '-18098621': '–¢–µ–ª–µ2',  # –¢–µ–ª–µ2
    '-50353992': '–ô–æ—Ç–∞',   # –ô–æ—Ç–∞
    '-3785': '–ú–µ–≥–∞—Ñ–æ–Ω'     # –ú–µ–≥–∞—Ñ–æ–Ω
}

VK_TOKEN = '954e97ed954e97ed954e97ed2d967306909954e954e97edfc65b931ccd5ae0f3c2a7afe'

# MWS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
MWS_URL = "https://tables.mws.ru/fusion/v1/datasheets/dstRtSXBewJh8lLCNz/records"
MWS_HEADERS = {
    "Authorization": "Bearer uskSID2MFKEnL7AVNUdLrnn",
    "Content-Type": "application/json"
}
MWS_PARAMS = {
    "viewId": "viwYvxvon7TBU",
    "fieldKey": "name"
}

# –õ–∏–º–∏—Ç –ø–æ—Å—Ç–æ–≤ –Ω–∞ –≥—Ä—É–ø–ø—É
MAX_POSTS_PER_GROUP = 8000

# –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –¥–ª—è –ø–æ—Å—Ç–æ–≤ (–ø–æ—Å—Ç—ã –¥–æ —ç—Ç–æ–π –¥–∞—Ç—ã –Ω–µ —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è)
MIN_POST_DATE = datetime(2025, 10, 11)

# –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–ø–∏—Å—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
LAST_UPDATE_RECORD_ID = "last_update_tracker"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–æ–Ω–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞ (—á—Ç–æ–±—ã –Ω–µ –Ω–∞–≥—Ä—É–∂–∞—Ç—å —Å–µ—Ä–≤–µ—Ä)
BACKGROUND_MODE = True
BACKGROUND_DELAY = 0.1  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å—á–µ—Ç—á–∏–∫–∏
success_count = 0
error_count = 0
skipped_duplicates = 0
counter_lock = Lock()

# –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö post_id –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
existing_post_ids = set()

class FastVKDataCollector:
    def __init__(self, vk_token, api_version='5.199'):
        self.vk_token = vk_token
        self.api_version = api_version
        self.base_url = 'https://api.vk.com/method/'
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

    def get_wall_posts_fast(self, owner_id, offset=0, count=100):
        """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å—Ç–æ–≤ –±–µ–∑ —Ä–µ—Ç—Ä–∞–µ–≤"""
        time.sleep(0.05)  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞

        method = 'wall.get'
        params = {
            'access_token': self.vk_token,
            'owner_id': owner_id,
            'v': self.api_version,
            'offset': offset,
            'count': count,
            'extended': 0
        }

        try:
            response = self.session.get(f"{self.base_url}{method}", params=params, timeout=5)
            response.raise_for_status()
            data = response.json()

            if 'error' in data:
                error_code = data['error'].get('error_code')
                if error_code in [6, 9, 29]:  # Rate limit –æ—à–∏–±–∫–∏
                    time.sleep(1)
                return None

            return data

        except Exception:
            return None

    def calculate_er(self, likes, reposts, comments, views):
        if not views or views == 0:
            return 0
        return ((likes + reposts + comments) / views) * 100

    def categorize_efficiency(self, er):
        if er >= 8:
            return "–í—ã—Å–æ–∫–∞—è"
        elif er >= 4:
            return "–°—Ä–µ–¥–Ω—è—è"
        elif er >= 2:
            return "–ù–∏–∑–∫–∞—è"
        else:
            return "–û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è"

    def extract_post_data_fast(self, post, group_name):
        try:
            post_id = post.get('id')
            owner_id = post.get('owner_id')
            date_timestamp = post.get('date')
            text = post.get('text', '')

            likes = post.get('likes', {}).get('count', 0)
            reposts = post.get('reposts', {}).get('count', 0)
            comments = post.get('comments', {}).get('count', 0)
            views = post.get('views', {}).get('count') if post.get('views') else 0

            # –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            title = ''
            for attachment in post.get('attachments', [])[:1]:
                attachment_type = attachment.get('type')
                if attachment_type in ['link', 'video']:
                    attachment_data = attachment.get(attachment_type, {})
                    title = attachment_data.get('title', '')[:200]
                    break

            er = self.calculate_er(likes, reposts, comments, views)
            efficiency = self.categorize_efficiency(er)

            return {
                'id_group': owner_id,
                'group_name': group_name,
                'id_post': post_id,
                'date_time': date_timestamp,
                'title': title,
                'text': text[:500],
                'views': views,
                'likes': likes,
                'reposts': reposts,
                'comments_count': comments,
                'ER': round(er, 2),
                'Efficiency': efficiency,
                'day_of_week': ["–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫", "–í—Ç–æ—Ä–Ω–∏–∫", "–°—Ä–µ–¥–∞", "–ß–µ—Ç–≤–µ—Ä–≥", "–ü—è—Ç–Ω–∏—Ü–∞", "–°—É–±–±–æ—Ç–∞", "–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ"][datetime.fromtimestamp(date_timestamp).weekday()],
                'date': datetime.fromtimestamp(date_timestamp).strftime('%Y-%m-%d'),
                'time_period': self.get_time_period_fast(date_timestamp),
                'len_text': len(text)
            }

        except Exception:
            return None

    def get_time_period_fast(self, timestamp):
        hour = datetime.fromtimestamp(timestamp).hour
        if 6 <= hour < 12:
            return "–£—Ç—Ä–æ"
        elif 12 <= hour < 18:
            return "–î–µ–Ω—å"
        elif 18 <= hour < 24:
            return "–í–µ—á–µ—Ä"
        else:
            return "–ù–æ—á—å"

def load_existing_post_ids():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ post_id –∏–∑ —Ç–∞–±–ª–∏—Ü—ã MWS –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
    global existing_post_ids
    
    print("üìã –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö post_id –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")
    
    try:
        all_ids = set()
        page_size = 1000  # –ú–∞–∫—Å–∏–º—É–º 1000 –∑–∞–ø–∏—Å–µ–π –∑–∞ –∑–∞–ø—Ä–æ—Å –≤ MWS Tables
        page_num = 1
        
        while True:
            params = {
                **MWS_PARAMS,
                "pageSize": page_size,
                "pageNum": page_num,
                "fields": "post_id"  # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ post_id –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç—Ä–∞—Ñ–∏–∫–∞
            }
            
            response = requests.get(
                MWS_URL,
                params=params,
                headers=MWS_HEADERS,
                timeout=30
            )
            
            if response.status_code != 200:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {response.status_code}")
                break
            
            data = response.json()
            records = data.get('data', {}).get('records', [])
            
            if not records:
                break
            
            for record in records:
                post_id = record.get('fields', {}).get('post_id')
                if post_id:
                    all_ids.add(str(post_id))
            
            print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(records)} –∑–∞–ø–∏—Å–µ–π, –≤—Å–µ–≥–æ: {len(all_ids)}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            total = data.get('data', {}).get('total', 0)
            if page_num * page_size >= total:
                break
            
            page_num += 1
            
            # –§–æ–Ω–æ–≤—ã–π —Ä–µ–∂–∏–º: –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
            if BACKGROUND_MODE:
                time.sleep(BACKGROUND_DELAY)
        
        existing_post_ids = all_ids
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(existing_post_ids)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö post_id")
        return existing_post_ids
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ post_id: {e}")
        return set()


def get_last_update_date():
    """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ —Ç–∞–±–ª–∏—Ü—ã"""
    try:
        params = {
            **MWS_PARAMS,
            "recordIds": LAST_UPDATE_RECORD_ID
        }

        response = requests.get(
            MWS_URL,
            params=params,
            headers=MWS_HEADERS,
            timeout=10
        )

        if response.status_code == 200:
            data = response.json()
            if data and 'data' in data and data['data']:
                record = data['data'][0]
                post_date_time = record.get('fields', {}).get('post_date_time')
                if post_date_time:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥ –≤ —Å–µ–∫—É–Ω–¥—ã
                    timestamp = post_date_time / 1000
                    last_update_date = datetime.fromtimestamp(timestamp)
                    print(f"üìÖ –ù–∞–π–¥–µ–Ω–∞ –¥–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ —Ç–∞–±–ª–∏—Ü–µ: {last_update_date}")
                    # –ï—Å–ª–∏ –¥–∞—Ç–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ —Ä–∞–Ω—å—à–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é
                    if last_update_date < MIN_POST_DATE:
                        print(f"‚ö†Ô∏è –î–∞—Ç–∞ –≤ —Ç–∞–±–ª–∏—Ü–µ —Ä–∞–Ω—å—à–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º: {MIN_POST_DATE}")
                        return MIN_POST_DATE
                    return last_update_date

        # –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É
        print(f"‚ö†Ô∏è –ó–∞–ø–∏—Å—å –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É: {MIN_POST_DATE}")
        return MIN_POST_DATE

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞—Ç—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É: {MIN_POST_DATE}")
        return MIN_POST_DATE

def upload_batch_to_mws(posts_data):
    global success_count, error_count

    if not posts_data:
        return 0
    
    # –§–æ–Ω–æ–≤—ã–π —Ä–µ–∂–∏–º: –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –ø–∞—É–∑—É
    if BACKGROUND_MODE:
        time.sleep(BACKGROUND_DELAY)

    records = []
    for post in posts_data:
        records.append({
            "post_id": str(post['id_post']),
            "title": str(post['title']),
            "text": str(post['text']),
            "attachment_description": "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
            "views": int(post['views']),
            "likes": int(post['likes']),
            "reposts": int(post['reposts']),
            "comments_count": int(post['comments_count']),
            "post_date_time": int(post['date_time']) * 1000,
            "owner_id": str(post['group_name']),  # –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã –≤–º–µ—Å—Ç–æ ID
            "ER": float(post['ER']),
            "Efficiency": str(post['Efficiency']),
            "day_of_week": str(post['day_of_week']),
            "post_date": int(post['date_time']) * 1000,
            "time_period": str(post['time_period']),
            "len_text": int(post['len_text'])
        })

    data = {
        "records": [{'fields': record} for record in records],
        "fieldKey": "name"
    }

    try:
        response = requests.post(
            MWS_URL,
            params=MWS_PARAMS,
            headers=MWS_HEADERS,
            json=data,
            timeout=10
        )

        if response.status_code in [200, 201]:
            with counter_lock:
                success_count += len(posts_data)
            return len(posts_data)
        else:
            # –ï—Å–ª–∏ –±–∞—Ç—á –Ω–µ –ø—Ä–æ—à–µ–ª, –ø—Ä–æ–±—É–µ–º –ø–æ –æ–¥–Ω–æ–º—É
            successful = 0
            for post in posts_data:
                if upload_single_post_fast(post):
                    successful += 1
            return successful

    except Exception:
        # Fallback –Ω–∞ –æ–¥–∏–Ω–æ—á–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É
        successful = 0
        for post in posts_data:
            if upload_single_post_fast(post):
                successful += 1
        return successful

def upload_single_post_fast(post_data):
    global success_count, error_count
    
    # –§–æ–Ω–æ–≤—ã–π —Ä–µ–∂–∏–º: –¥–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –ø–∞—É–∑—É
    if BACKGROUND_MODE:
        time.sleep(BACKGROUND_DELAY * 0.5)

    try:
        record = {
            "post_id": str(post_data['id_post']),
            "title": str(post_data['title']),
            "text": str(post_data['text']),
            "attachment_description": "–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç",
            "views": int(post_data['views']),
            "likes": int(post_data['likes']),
            "reposts": int(post_data['reposts']),
            "comments_count": int(post_data['comments_count']),
            "post_date_time": int(post_data['date_time']) * 1000,
            "owner_id": str(post_data['group_name']),  # –ù–∞–∑–≤–∞–Ω–∏–µ –≥—Ä—É–ø–ø—ã –≤–º–µ—Å—Ç–æ ID
            "ER": float(post_data['ER']),
            "Efficiency": str(post_data['Efficiency']),
            "day_of_week": str(post_data['day_of_week']),
            "post_date": int(post_data['date_time']) * 1000,
            "time_period": str(post_data['time_period']),
            "len_text": int(post_data['len_text'])
        }

        data = {
            "records": [{'fields': record}],
            "fieldKey": "name"
        }

        response = requests.post(
            MWS_URL,
            params=MWS_PARAMS,
            headers=MWS_HEADERS,
            json=data,
            timeout=5
        )

        if response.status_code in [200, 201]:
            with counter_lock:
                success_count += 1
            return True
        else:
            error_text = response.text.lower()
            if "duplicate" in error_text or "—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç" in error_text:
                with counter_lock:
                    success_count += 1
                return True
            return False

    except Exception:
        with counter_lock:
            error_count += 1
        return False

def find_start_offset(collector, owner_id, total_posts, cutoff_date):
    """–ë–∏–Ω–∞—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤ –¥–æ cutoff –¥–∞—Ç—ã"""
    print("üîç –ë—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫ —Å—Ç–∞—Ä—Ç–æ–≤–æ–π –ø–æ–∑–∏—Ü–∏–∏...")

    low = 0
    high = min(total_posts, 2000)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ–∏—Å–∫ –ø–µ—Ä–≤—ã–º–∏ 2000 –ø–æ—Å—Ç–∞–º–∏
    cutoff_timestamp = cutoff_date.timestamp()

    while low <= high:
        mid = (low + high) // 2
        print(f"   –ü—Ä–æ–≤–µ—Ä–∫–∞ offset {mid}...")

        data = collector.get_wall_posts_fast(owner_id, mid, 1)
        if not data or not data['response']['items']:
            break

        post = data['response']['items'][0]
        post_timestamp = post.get('date', 0)

        if post_timestamp > cutoff_timestamp:
            low = mid + 1
        else:
            high = mid - 1

    # –ù–∞—á–∏–Ω–∞–µ–º —Å –Ω–∞–π–¥–µ–Ω–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
    start_offset = max(0, low - 50)  # –ù–µ–º–Ω–æ–≥–æ –æ—Ç—Å—Ç—É–ø–∞–µ–º –Ω–∞–∑–∞–¥ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    print(f"–ù–∞—á–∏–Ω–∞–µ–º —Å –æ—Ç—Å—Ç—É–ø–∞: {start_offset}")
    return start_offset

def collect_group_posts_optimized(owner_id, group_name, cutoff_date):
    global success_count, error_count

    collector = FastVKDataCollector(VK_TOKEN)

    print(f"\nüìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã: {group_name} ({owner_id})")

    # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    test_data = collector.get_wall_posts_fast(owner_id, 0, 1)
    if not test_data:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä—É–ø–ø—ã {group_name}")
        return 0

    total_posts = test_data['response']['count']
    print(f"üìà –í—Å–µ–≥–æ –ø–æ—Å—Ç–æ–≤: {total_posts}")

    if total_posts == 0:
        return 0

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ä—Ç–æ–≤—É—é –ø–æ–∑–∏—Ü–∏—é
    start_offset = find_start_offset(collector, owner_id, total_posts, cutoff_date)

    collected = 0
    offset = start_offset
    batch_size = 100
    cutoff_timestamp = cutoff_date.timestamp()
    last_progress_report = 0  # –î–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–≤–æ–¥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

    with tqdm(total=MAX_POSTS_PER_GROUP, desc=f"–ì—Ä—É–ø–ø–∞ {group_name}") as pbar:
        while collected < MAX_POSTS_PER_GROUP:
            # –±–∞—Ç—á
            data = collector.get_wall_posts_fast(owner_id, offset, batch_size)
            if not data:
                break

            posts = data['response'].get('items', [])
            if not posts:
                break
            
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –≤ –ª–æ–≥ (–∫–∞–∂–¥—ã–µ 1000 –ø–æ—Å—Ç–æ–≤)
            if collected - last_progress_report >= 1000:
                print(f"   üìä {group_name}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {collected}/{MAX_POSTS_PER_GROUP} ({collected*100//MAX_POSTS_PER_GROUP}%)", flush=True)
                last_progress_report = collected

            # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å—Ç—ã
            valid_posts = []
            for post in posts:
                if collected >= MAX_POSTS_PER_GROUP:
                    break

                post_timestamp = post.get('date', 0)
                post_id = str(post.get('id', ''))
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç –ø–æ post_id
                if post_id in existing_post_ids:
                    with counter_lock:
                        global skipped_duplicates
                        skipped_duplicates += 1
                    collected += 1
                    pbar.update(1)
                    continue
                
                if post_timestamp <= cutoff_timestamp:
                    post_data = collector.extract_post_data_fast(post, group_name)
                    if post_data:
                        valid_posts.append(post_data)
                        # –î–æ–±–∞–≤–ª—è–µ–º –≤ set —á—Ç–æ–±—ã –Ω–µ –≤—Å—Ç–∞–≤–∏—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ –≤ —ç—Ç–æ–π –∂–µ —Å–µ—Å—Å–∏–∏
                        existing_post_ids.add(post_id)
                        collected += 1
                        pbar.update(1)
                else:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–≤—ã–µ –ø–æ—Å—Ç—ã
                    collected += 1
                    pbar.update(1)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–µ –ø–æ—Å—Ç—ã –±–∞—Ç—á–µ–º
            if valid_posts:
                upload_batch_to_mws(valid_posts)
            
            # –§–æ–Ω–æ–≤—ã–π —Ä–µ–∂–∏–º: –ø–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
            if BACKGROUND_MODE:
                time.sleep(BACKGROUND_DELAY * 2)

            offset += batch_size

            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –≤—Å–µ –ø–æ—Å—Ç—ã –≤ –±–∞—Ç—á–µ –Ω–æ–≤—ã–µ, —É—Å–∫–æ—Ä—è–µ–º—Å—è
            if len(valid_posts) == 0 and len(posts) > 0:
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —à–∞–≥ –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞ –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤
                skip_ahead = min(500, MAX_POSTS_PER_GROUP - collected)
                if skip_ahead > 100:
                    offset += skip_ahead - batch_size
                    pbar.update(skip_ahead)
                    collected += skip_ahead
                    print(f"‚ö° –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {skip_ahead} –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤")

    print(f"‚úÖ –ì—Ä—É–ø–ø–∞ {group_name}: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {collected} –ø–æ—Å—Ç–æ–≤")
    return collected

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
    global success_count, error_count, skipped_duplicates

    print("üöÄ –ó–ê–ü–£–°–ö –°–ë–û–†–ê –î–ê–ù–ù–´–• –ò–ó VK")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ post_id –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    load_existing_post_ids()

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
    CUTOFF_DATE = get_last_update_date()

    print(f"üìÖ –°–±–æ—Ä –ø–æ—Å—Ç–æ–≤ –¥–æ: {CUTOFF_DATE}")
    print(f"üéØ –õ–∏–º–∏—Ç: {MAX_POSTS_PER_GROUP} –ø–æ—Å—Ç–æ–≤ –Ω–∞ –≥—Ä—É–ø–ø—É")
    print(f"üìä –ì—Ä—É–ø–ø—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(VK_GROUPS)}")
    for group_id, group_name in VK_GROUPS.items():
        print(f"   - {group_name} ({group_id})")
    print("=" * 60)

    start_time = time.time()
    total_processed = 0

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥—Ä—É–ø–ø—ã —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é
    for i, (group_id, group_name) in enumerate(VK_GROUPS.items()):
        print(f"\n{'='*50}")
        print(f"üîÑ –ì—Ä—É–ø–ø–∞ {i+1}/{len(VK_GROUPS)}: {group_name}")
        print(f"{'='*50}")

        processed = collect_group_posts_optimized(group_id, group_name, CUTOFF_DATE)
        total_processed += processed

        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏ (—É–≤–µ–ª–∏—á–µ–Ω–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ)
        if i < len(VK_GROUPS) - 1:
            pause = 2.0 if BACKGROUND_MODE else 0.5
            time.sleep(pause)

    total_time = time.time() - start_time

    print(f"\n{'='*60}")
    print("üéâ –§–ò–ù–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ë–û–†–ê –î–ê–ù–ù–´–•")
    print(f"{'='*60}")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {success_count}")
    print(f"üîÑ –ü—Ä–æ–ø—É—â–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {skipped_duplicates}")
    print(f"‚ùå –û—à–∏–±–æ–∫: {error_count}")
    print(f"üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_processed}")
    print(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.1f} —Å–µ–∫")

    if total_processed > 0:
        speed = total_processed / total_time
        print(f"‚ö° –°–∫–æ—Ä–æ—Å—Ç—å: {speed:.1f} –ø–æ—Å—Ç–æ–≤/—Å–µ–∫")
        print(f"üìà –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {speed * 60:.1f} –ø–æ—Å—Ç–æ–≤/–º–∏–Ω")

def run_background():
    """–ó–∞–ø—É—Å–∫ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ —Å –Ω–∏–∑–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º"""
    import os
    try:
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–∞ (nice)
        os.nice(10)
        print("üîΩ –ó–∞–ø—É—â–µ–Ω –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ —Å –Ω–∏–∑–∫–∏–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º")
    except (OSError, AttributeError):
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –Ω–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤ –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ")
    
    main()

if __name__ == "__main__":
    if BACKGROUND_MODE:
        run_background()
    else:
        main()